{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fcfe31c-f98c-4f34-8e8e-3b42157e10d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, ResNet50\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Add this at the top of your notebook after imports\n",
    "import keras\n",
    "keras.config.enable_unsafe_deserialization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77f90261-7689-4f55-a320-322fd341f307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: C:\\Users\\mar4u\\Documents\\DS-Test-2025\\task2\\scripts\n",
      "Base directory: C:\\Users\\mar4u\\Documents\\DS-Test-2025\\task2\n",
      "NER model directory: ✓ EXISTS at C:\\Users\\mar4u\\Documents\\DS-Test-2025\\task2\\models\\ner_model\\final\n",
      "Image classifier model: ✓ EXISTS at C:\\Users\\mar4u\\Documents\\DS-Test-2025\\task2\\models\\animal_classifier_final.keras\n"
     ]
    }
   ],
   "source": [
    "# Define base directory\n",
    "base_dir = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "print(\"Base directory:\", base_dir)\n",
    "\n",
    "# Check required paths\n",
    "paths_to_check = {\n",
    "    \"NER model directory\": os.path.join(base_dir, \"models\", \"ner_model\", \"final\"),\n",
    "    \"Image classifier model\": os.path.join(base_dir, \"models\", \"animal_classifier_final.keras\")\n",
    "}\n",
    "\n",
    "for name, path in paths_to_check.items():\n",
    "    exists = os.path.exists(path)\n",
    "    print(f\"{name}: {'✓ EXISTS' if exists else '✗ MISSING'} at {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ba270cb-5bfe-4e22-bb7e-4d6520c14f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnimalPipeline:\n",
    "    def __init__(self):\n",
    "        self.BASE_DIR = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "        \n",
    "        # Load NER model\n",
    "        self.ner_model_path = os.path.join(self.BASE_DIR, \"models\", \"ner_model\", \"final\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.ner_model_path)\n",
    "        self.ner_model = AutoModelForTokenClassification.from_pretrained(self.ner_model_path)\n",
    "        \n",
    "        # Define class names for the image classifier\n",
    "        self.class_names = ['butterfly', 'cat', 'chicken', 'cow', 'dog', 'elephant', 'horse', 'sheep', 'spider', 'squirrel']\n",
    "        self.image_model = self.create_and_load_image_model()\n",
    "    \n",
    "    def create_and_load_image_model(self):\n",
    "        # Create model architecture using ResNet50 as base\n",
    "        base_model = ResNet50(\n",
    "            input_shape=(224, 224, 3),\n",
    "            include_top=False,\n",
    "            weights=\"imagenet\"\n",
    "        )\n",
    "        base_model.trainable = False\n",
    "        \n",
    "        model = models.Sequential([\n",
    "            base_model,\n",
    "            layers.GlobalAveragePooling2D(),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dense(512, activation='relu'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dropout(0.5),\n",
    "            layers.Dense(256, activation='relu'),\n",
    "            layers.Dropout(0.3),\n",
    "            layers.Dense(len(self.class_names), activation='softmax')\n",
    "        ])\n",
    "        \n",
    "        # Load trained weights\n",
    "        model_path = os.path.join(self.BASE_DIR, \"models\", \"animal_classifier_final.keras\")\n",
    "        if os.path.exists(model_path):\n",
    "            old_model = tf.keras.models.load_model(model_path)\n",
    "            # Copy weights, skipping the Lambda layer\n",
    "            for new_layer, old_layer in zip(model.layers, old_model.layers[1:]):\n",
    "                new_layer.set_weights(old_layer.get_weights())\n",
    "        else:\n",
    "            print(f\"Warning: Model file not found at {model_path}\")\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def extract_animal_from_text(self, text):\n",
    "        # Tokenize input text\n",
    "        inputs = self.tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=128)\n",
    "        \n",
    "        # Get predictions\n",
    "        with torch.no_grad():\n",
    "            outputs = self.ner_model(**inputs)\n",
    "            predictions = torch.argmax(outputs.logits, dim=2)\n",
    "        \n",
    "        # Extract tokens labeled as ANIMAL\n",
    "        tokens = self.tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
    "        animal_tokens = []\n",
    "        current_animal = []\n",
    "        \n",
    "        for token, pred in zip(tokens, predictions[0]):\n",
    "            if pred == 1:  # ANIMAL label\n",
    "                if token.startswith(\"##\"):\n",
    "                    current_animal.append(token[2:])\n",
    "                else:\n",
    "                    if current_animal:\n",
    "                        animal_tokens.append(\"\".join(current_animal))\n",
    "                        current_animal = []\n",
    "                    current_animal.append(token)\n",
    "            else:\n",
    "                if current_animal:\n",
    "                    animal_tokens.append(\"\".join(current_animal))\n",
    "                    current_animal = []\n",
    "        \n",
    "        if current_animal:\n",
    "            animal_tokens.append(\"\".join(current_animal))\n",
    "        \n",
    "        # Clean up extracted animal names\n",
    "        animals = [animal.lower() for animal in animal_tokens if animal not in [\"[CLS]\", \"[SEP]\", \"[PAD]\"]]\n",
    "        return animals[0] if animals else None\n",
    "    \n",
    "    def classify_image(self, image_path):\n",
    "        # Load and preprocess image\n",
    "        img = image.load_img(image_path, target_size=(224, 224))\n",
    "        img_array = image.img_to_array(img)\n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "        img_array = preprocess_input(img_array)\n",
    "        \n",
    "        # Get prediction\n",
    "        predictions = self.image_model.predict(img_array, verbose=0)\n",
    "        predicted_class = self.class_names[np.argmax(predictions[0])]\n",
    "        confidence = np.max(predictions[0]) * 100\n",
    "        \n",
    "        return predicted_class, confidence\n",
    "    \n",
    "    def process(self, text, image_path):\n",
    "        \"\"\"\n",
    "        Process text and image to determine if they match.\n",
    "        Returns:\n",
    "            tuple: (boolean match result, dict with detailed information)\n",
    "        \"\"\"\n",
    "        # Extract animal from text\n",
    "        text_animal = self.extract_animal_from_text(text)\n",
    "        if not text_animal:\n",
    "            return False, {\n",
    "                \"error\": \"No animal mentioned in text\",\n",
    "                \"text_animal\": None,\n",
    "                \"image_animal\": None,\n",
    "                \"confidence\": 0\n",
    "            }\n",
    "        \n",
    "        # Classify image\n",
    "        image_animal, confidence = self.classify_image(image_path)\n",
    "        \n",
    "        # Check if animals match\n",
    "        match = text_animal.lower() == image_animal.lower()\n",
    "        \n",
    "        return match, {\n",
    "            \"text_animal\": text_animal,\n",
    "            \"image_animal\": image_animal,\n",
    "            \"confidence\": confidence,\n",
    "            \"match\": match\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3847c089-d581-49be-8511-0f94845af2e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing with text: There is a cat in the picture.\n",
      "Text mentions: cat\n",
      "Image shows: dog (confidence: 99.89%)\n",
      "Match: False\n",
      "\n",
      "Testing with text: I can see a dog.\n",
      "Text mentions: dog\n",
      "Image shows: chicken (confidence: 100.00%)\n",
      "Match: False\n",
      "\n",
      "Testing with text: Look at this elephant.\n",
      "Text mentions: elephant\n",
      "Image shows: cat (confidence: 44.92%)\n",
      "Match: False\n",
      "\n",
      "Testing with text: Here is the butterfly.\n",
      "Text mentions: butterfly\n",
      "Image shows: butterfly (confidence: 100.00%)\n",
      "Match: True\n"
     ]
    }
   ],
   "source": [
    "# Initialize the pipeline\n",
    "pipeline = AnimalPipeline()\n",
    "\n",
    "# Test cases with your actual images\n",
    "test_cases = [\n",
    "    {\n",
    "        \"text\": \"There is a cat in the picture.\",\n",
    "        \"image_path\": \"../test_img1.jpg\"  \n",
    "    },\n",
    "    {\n",
    "        \"text\": \"I can see a dog.\",\n",
    "        \"image_path\": \"../test_img2.jpg\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Look at this elephant.\",\n",
    "        \"image_path\": \"../test_img3.jpg\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Here is the butterfly.\",\n",
    "        \"image_path\": \"../test_img4.jpg\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Run tests\n",
    "for test in test_cases:\n",
    "    print(f\"\\nTesting with text: {test['text']}\")\n",
    "    try:\n",
    "        match, details = pipeline.process(test['text'], test['image_path'])\n",
    "        print(f\"Text mentions: {details['text_animal']}\")\n",
    "        print(f\"Image shows: {details['image_animal']} (confidence: {details['confidence']:.2f}%)\")\n",
    "        print(f\"Match: {match}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred with {test['image_path']}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa2f3d3-59c9-4126-96d9-c400da119e42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
