{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90b2cef3-cf22-434f-b7ce-de6eccdab524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/alessiocorrado99/animals10\n",
      "Dataset downloaded and extracted to: task2/dataset\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "# Authenticate\n",
    "api = KaggleApi()\n",
    "api.authenticate()\n",
    "\n",
    "# Download and extract dataset\n",
    "dataset_path = \"task2/dataset\"\n",
    "api.dataset_download_files(\"alessiocorrado99/animals10\", path=dataset_path, unzip=True)\n",
    "\n",
    "print(f\"Dataset downloaded and extracted to: {dataset_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f160abf-a1bc-4e20-bea6-07a77b67f4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1:\n",
      "Sentence: A squirrel appears in the picture\n",
      "Entities: [[2, 10, 'ANIMAL']]\n",
      "--------------------------------------------------\n",
      "Example 2:\n",
      "Sentence: There is a elephant in the picture\n",
      "Entities: [[11, 19, 'ANIMAL']]\n",
      "--------------------------------------------------\n",
      "Example 3:\n",
      "Sentence: I can see a .ipynb_checkpoints in this image\n",
      "Entities: [[12, 30, 'ANIMAL']]\n",
      "--------------------------------------------------\n",
      "Example 4:\n",
      "Sentence: A elephant appears in the picture\n",
      "Entities: [[2, 10, 'ANIMAL']]\n",
      "--------------------------------------------------\n",
      "Example 5:\n",
      "Sentence: The photo shows a sheep\n",
      "Entities: [[18, 23, 'ANIMAL']]\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load a small preview of the dataset\n",
    "with open(\"task2/dataset/ner_training_data/train.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Print 5 sample sentences\n",
    "for i, item in enumerate(data[:5]):\n",
    "    print(f\"Example {i+1}:\")\n",
    "    print(\"Sentence:\", item[\"sentence\"])\n",
    "    print(\"Entities:\", item[\"entities\"])\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5346862-8241-429a-9d95-57121a7f7f28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
